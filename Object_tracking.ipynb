{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd55747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tracker import Object_Tracker\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "from deep_sort import generate_detections as gdet\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db687e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker= Object_Tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5379f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= 'C:\\\\dataset2014\\\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8474b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badWeather', 'baseline', 'cameraJitter', 'dynamicBackground', 'intermittentObjectMotion', 'lowFramerate', 'nightVideos', 'PTZ', 'shadow', 'thermal', 'turbulence']\n"
     ]
    }
   ],
   "source": [
    "all_items = os.listdir(data_dir)\n",
    "categories = [item for item in all_items if os.path.isdir(os.path.join(data_dir, item))]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a27dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 125.9ms\n",
      "Speed: 5.0ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "img=  'C:\\\\dataset2014\\\\results\\\\badWeather\\\\skating\\\\in000001.jpg'\n",
    "img= cv2.imread(img)\n",
    "results= model(img)\n",
    "\n",
    "names=results[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982cb8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb2a564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 320, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e50979",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for j in range(10)]\n",
    "\n",
    "detection_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6240325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Toqa Alaa\\\\deep_learning\\\\Real-time-object-tracking'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0279b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(detections,  threshold):\n",
    "\n",
    "    if len(detections) == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    boxes= [box[0:4] for box in detections]\n",
    "    scores= [box[4].item() for box in detections]\n",
    "    classes= [box[5] for box in detections]\n",
    "    \n",
    "    boxes= np.array(boxes)\n",
    "    scores= np.array(scores)\n",
    "    classes= np.array(classes)\n",
    "\n",
    "    # Initialize an empty list to store the selected boxes.\n",
    "    selected_boxes = []\n",
    "    selected_scores= []\n",
    "    selected_classes= []\n",
    "\n",
    "    # Sort the boxes by their confidence scores in descending order.\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    boxes = boxes[sorted_indices]\n",
    "    scores = scores[sorted_indices]\n",
    "    classes= classes[sorted_indices]\n",
    "\n",
    "    while len(boxes) > 0:\n",
    "        # Select the box with the highest confidence score and add it to the selected list.\n",
    "        selected_boxes.append(boxes[0])\n",
    "        selected_scores.append(scores[0])\n",
    "        selected_classes.append(classes[0])\n",
    "\n",
    "        # Calculate the IoU (Intersection over Union) between the selected box and the remaining boxes.\n",
    "        iou = calculate_iou(selected_boxes[-1], boxes[1:])\n",
    "\n",
    "        # Filter out the boxes with IoU greater than or equal to the threshold.\n",
    "        mask = iou < threshold\n",
    "        boxes = boxes[1:][mask]\n",
    "        scores = scores[1:][mask]\n",
    "\n",
    "    return selected_boxes, selected_scores, selected_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2094d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, boxes2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1 = np.maximum(x1, boxes2[:, 0])\n",
    "    y1 = np.maximum(y1, boxes2[:, 1])\n",
    "    x2 = np.minimum(x2, boxes2[:, 2])\n",
    "    y2 = np.minimum(y2, boxes2[:, 3])\n",
    "\n",
    "    intersection_area = np.maximum(0, x2 - x1 + 1) * np.maximum(0, y2 - y1 + 1)\n",
    "    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    boxes2_area = (boxes2[:, 2] - boxes2[:, 0] + 1) * (boxes2[:, 3] - boxes2[:, 1] + 1)\n",
    "\n",
    "    iou = intersection_area / (box1_area + boxes2_area - intersection_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f058bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='C:\\\\dataset2014\\\\results\\\\baseline\\\\highway'\n",
    "video_path= 'traffic_video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003ee76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(video_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec088f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408ef1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 77.8ms\n",
      "Speed: 11.0ms preprocess, 77.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[607, 307, 633, 336, 0.6374568939208984, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 car, 82.8ms\n",
      "Speed: 3.0ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 70.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[607, 307, 633, 336, 0.6399165391921997, 'car']]\n",
      "[[606, 307, 633, 336, 0.6196421980857849, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 56.8ms\n",
      "Speed: 3.0ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[605, 308, 633, 337, 0.6649579405784607, 'car']]\n",
      "[[604, 308, 632, 338, 0.5958523154258728, 'car']]\n",
      "[[1102, 698, 1300, 764, 0.7092212438583374, 'car'], [601, 309, 631, 339, 0.6431823372840881, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 cars, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 76.8ms\n",
      "Speed: 3.0ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1081, 678, 1281, 763, 0.7404282093048096, 'car'], [600, 309, 631, 339, 0.6189277768135071, 'car']]\n",
      "[[1050, 637, 1229, 765, 0.7544621229171753, 'car'], [599, 309, 628, 341, 0.5587347745895386, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 cars, 86.8ms\n",
      "Speed: 3.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1034, 621, 1199, 738, 0.5695949196815491, 'car'], [598, 310, 628, 342, 0.49722540378570557, 'car']]\n",
      "[[1019, 604, 1178, 714, 0.6427969336509705, 'car'], [596, 309, 627, 344, 0.5056697130203247, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 cars, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1007, 589, 1156, 698, 0.7221307754516602, 'car'], [595, 309, 627, 345, 0.4473961591720581, 'car']]\n",
      "[[993, 574, 1135, 677, 0.6083101630210876, 'car'], [594, 309, 628, 346, 0.4808262288570404, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 cars, 72.1ms\n",
      "Speed: 2.0ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 64.8ms\n",
      "Speed: 3.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 64.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[973, 553, 1101, 636, 0.6526740193367004, 'car'], [590, 317, 622, 349, 0.6280165314674377, 'car']]\n",
      "[[963, 543, 1084, 624, 0.6488127708435059, 'car'], [589, 323, 620, 350, 0.6060664653778076, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 86.8ms\n",
      "Speed: 2.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[588, 317, 619, 350, 0.6298187971115112, 'car'], [955, 531, 1066, 616, 0.5315497517585754, 'car']]\n",
      "[[945, 523, 1055, 597, 0.7335258722305298, 'car'], [585, 317, 619, 352, 0.5994157195091248, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 cars, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[584, 319, 619, 353, 0.6253370046615601, 'car'], [938, 512, 1044, 591, 0.5906488299369812, 'car']]\n",
      "[[582, 320, 620, 354, 0.634755551815033, 'car'], [923, 500, 1019, 566, 0.6043171286582947, 'car'], [625, 296, 647, 312, 0.3027831017971039, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 cars, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[916, 493, 1008, 557, 0.7044394016265869, 'car'], [581, 320, 619, 355, 0.6185693144798279, 'car']]\n",
      "[[911, 485, 999, 550, 0.6121188998222351, 'car'], [580, 320, 617, 357, 0.5277774930000305, 'car'], [625, 295, 648, 314, 0.30623337626457214, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 6 cars, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[904, 478, 990, 538, 0.6549689173698425, 'car'], [578, 321, 615, 359, 0.4976878762245178, 'car'], [625, 295, 648, 314, 0.3494219481945038, 'car']]\n",
      "[[574, 321, 618, 360, 0.49687233567237854, 'car'], [898, 475, 985, 531, 0.4597446322441101, 'car'], [624, 296, 647, 314, 0.3942779004573822, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 cars, 74.8ms\n",
      "Speed: 2.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 71.8ms\n",
      "Speed: 2.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[887, 463, 967, 521, 0.7183414697647095, 'car'], [570, 331, 605, 363, 0.5239184498786926, 'car'], [623, 294, 647, 315, 0.39717555046081543, 'car']]\n",
      "[[883, 458, 960, 508, 0.6242813467979431, 'car'], [569, 332, 604, 365, 0.5623509883880615, 'car'], [623, 292, 647, 315, 0.4009203016757965, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 cars, 65.8ms\n",
      "Speed: 3.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 86.8ms\n",
      "Speed: 3.0ms preprocess, 86.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[567, 335, 604, 366, 0.623421847820282, 'car'], [622, 292, 648, 315, 0.3829375207424164, 'car'], [878, 452, 951, 510, 0.3571438193321228, 'car']]\n",
      "[[875, 449, 948, 504, 0.6983095407485962, 'car'], [565, 339, 602, 367, 0.5995883345603943, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 cars, 68.8ms\n",
      "Speed: 3.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 63.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[565, 337, 601, 369, 0.6620962023735046, 'car'], [869, 441, 941, 494, 0.62066650390625, 'car']]\n",
      "[[864, 434, 928, 475, 0.47896793484687805, 'car'], [564, 336, 604, 373, 0.47777917981147766, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 60.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[865, 431, 922, 461, 0.6436747312545776, 'car'], [562, 338, 598, 372, 0.4876951277256012, 'car']]\n",
      "[[857, 428, 915, 459, 0.5555991530418396, 'car'], [558, 338, 597, 373, 0.5491067171096802, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 60.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[853, 423, 914, 463, 0.6168088912963867, 'car'], [557, 337, 596, 374, 0.4938786029815674, 'car']]\n",
      "[[555, 340, 591, 376, 0.5008469223976135, 'car'], [851, 420, 912, 461, 0.46970903873443604, 'car']]\n",
      "[[550, 343, 589, 379, 0.4778004586696625, 'car'], [846, 415, 899, 445, 0.42138296365737915, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 cars, 71.8ms\n",
      "Speed: 2.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 64.8ms\n",
      "Speed: 3.0ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[547, 346, 588, 382, 0.6935564875602722, 'car'], [570, 326, 606, 347, 0.4034211039543152, 'car'], [841, 409, 898, 445, 0.3866082429885864, 'car']]\n",
      "[[545, 348, 584, 383, 0.6013485789299011, 'car'], [570, 326, 604, 347, 0.385246217250824, 'car'], [838, 407, 896, 441, 0.33653923869132996, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 cars, 77.8ms\n",
      "Speed: 2.0ms preprocess, 77.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[543, 348, 584, 385, 0.6444501280784607, 'car'], [569, 326, 604, 349, 0.46315085887908936, 'car'], [615, 300, 641, 321, 0.3334594666957855, 'car'], [836, 404, 904, 443, 0.31241124868392944, 'car']]\n",
      "[[539, 349, 584, 388, 0.6411684155464172, 'car'], [834, 400, 889, 433, 0.5957823991775513, 'car'], [568, 326, 603, 353, 0.5336233377456665, 'car'], [613, 302, 641, 322, 0.31750786304473877, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 cars, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[536, 352, 576, 393, 0.603405237197876, 'car'], [565, 327, 604, 355, 0.5601300001144409, 'car'], [829, 398, 890, 436, 0.5005990862846375, 'car'], [611, 303, 639, 322, 0.33033818006515503, 'car']]\n",
      "[[535, 354, 573, 393, 0.6858079433441162, 'car'], [564, 329, 603, 356, 0.5305817723274231, 'car'], [828, 395, 884, 430, 0.4854579269886017, 'car'], [608, 305, 639, 325, 0.3217278718948364, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 cars, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[532, 354, 572, 394, 0.6979907155036926, 'car'], [826, 391, 883, 428, 0.5527169704437256, 'car'], [562, 330, 605, 359, 0.5520931482315063, 'car'], [608, 306, 639, 325, 0.38329607248306274, 'car']]\n",
      "[[530, 355, 571, 397, 0.7502177953720093, 'car'], [561, 330, 604, 358, 0.6323993802070618, 'car'], [823, 391, 885, 427, 0.41101792454719543, 'car'], [608, 306, 635, 326, 0.4075894355773926, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 cars, 66.8ms\n",
      "Speed: 3.0ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 61.8ms\n",
      "Speed: 3.0ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[527, 355, 570, 400, 0.6638322472572327, 'car'], [822, 388, 881, 422, 0.5744150280952454, 'car'], [561, 328, 606, 358, 0.49475204944610596, 'car'], [607, 306, 634, 326, 0.4870505928993225, 'car']]\n",
      "[[520, 358, 578, 407, 0.6349712014198303, 'car'], [818, 385, 876, 419, 0.5620149970054626, 'car'], [559, 332, 592, 358, 0.49176356196403503, 'car'], [606, 306, 634, 326, 0.471804141998291, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 cars, 68.8ms\n",
      "Speed: 4.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 65.8ms\n",
      "Speed: 2.0ms preprocess, 65.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517, 361, 590, 409, 0.8075671792030334, 'car'], [557, 333, 608, 361, 0.40263187885284424, 'car'], [815, 382, 868, 416, 0.3960164487361908, 'car'], [606, 307, 633, 326, 0.37846502661705017, 'car']]\n",
      "[[513, 363, 591, 411, 0.6226015090942383, 'car'], [814, 379, 869, 414, 0.41244497895240784, 'car'], [554, 338, 590, 360, 0.32361090183258057, 'car'], [605, 306, 631, 327, 0.3160513937473297, 'car']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "# start_time = time.time()\n",
    "\n",
    "# for img in os.listdir(data_path):\n",
    "#     frame = cv2.imread(os.path.join(data_path, img))\n",
    "    _, frame = vid.read()\n",
    "    # Perform object detection using YOLO on the current frame\n",
    "    results = model(frame)  \n",
    "\n",
    "    # Update the tracks using the DeepSort tracker\n",
    "    for result in results:\n",
    "        detections = []\n",
    "        \n",
    "\n",
    "        # Creating the detections array\n",
    "        for r in result.boxes.data:\n",
    "            x1, y1, x2, y2, score, class_id = r\n",
    "            x1 = int(x1)\n",
    "            x2 = int(x2)\n",
    "            y1 = int(y1)\n",
    "            y2 = int(y2)\n",
    "\n",
    "            class_id = int(class_id)\n",
    "            class_name= names[class_id]\n",
    "            if score>=0.3:\n",
    "                detections.append([x1, y1, x2, y2, score, class_name])\n",
    "            \n",
    "        \n",
    "       \n",
    "        boxes, score, classes= non_max_suppression(detections, 0.5)\n",
    "        detections=[]\n",
    "        for i in range(len(boxes)):\n",
    "            b= []\n",
    "            b.append(boxes[i][0])\n",
    "            b.append(boxes[i][1])\n",
    "            b.append(boxes[i][2])\n",
    "            b.append(boxes[i][3])\n",
    "            b.append(score[i])\n",
    "            b.append(classes[i])\n",
    "            \n",
    "            \n",
    "            detections.append(b)\n",
    "        \n",
    "        print(detections)\n",
    "    \n",
    "        tracker.update(frame, detections)\n",
    "        # Updating the tracks with the new frame\n",
    "        for track in tracker.tracks:\n",
    "            bbox = track.bbox\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            track_id = track.track_id\n",
    "            \n",
    "            \n",
    "\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (colors[track_id % len(colors)]), 3)\n",
    "\n",
    "            # Define the text you want to add\n",
    "            text = track.class_name\n",
    "\n",
    "            # Define the position where you want to place the text (adjust coordinates as needed)\n",
    "            text_x = int(x1)  # You can adjust the x-coordinate as needed\n",
    "            text_y = int(y1) - 10  # You can adjust the y-coordinate as needed\n",
    "\n",
    "            # Get the color of the rectangle\n",
    "            rectangle_color = colors[track_id % len(colors)]\n",
    "\n",
    "            # Get the size of the text to calculate the size of the background rectangle\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            background_width = text_width + 10\n",
    "            background_height = text_height + 10\n",
    "\n",
    "            # Define the position of the background rectangle\n",
    "            background_x = text_x\n",
    "            background_y = text_y - text_height\n",
    "\n",
    "            # Draw the background rectangle\n",
    "            cv2.rectangle(frame, (background_x, background_y), (background_x + background_width, background_y + background_height), rectangle_color, -1)\n",
    "\n",
    "            # Define the font and font scale\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "\n",
    "            # Define the color of the text (you can change this if needed)\n",
    "            text_color = (255, 255, 255)  # White color in BGR\n",
    "\n",
    "            # Add the text to the frame\n",
    "            cv2.putText(frame, text, (text_x, text_y), font, font_scale, text_color, 1, cv2.LINE_AA)\n",
    "        # Save the frame with tracking results\n",
    "        cv2.imshow('img', frame)\n",
    "        \n",
    "        frames.append(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef32721",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "frame_rate = 30  # Adjust this to your desired frame rate\n",
    "width, height = frames[0].shape[1], frames[0].shape[0]  # Use dimensions from the first frame\n",
    "\n",
    "# Create VideoWriter object\n",
    "out = cv2.VideoWriter(output_file, fourcc, frame_rate, (width, height))\n",
    "\n",
    "# Loop through the array of frames and write them to the video\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "\n",
    "# Optionally, you can also destroy any OpenCV windows that might be open\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c85c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6b379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ada15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
